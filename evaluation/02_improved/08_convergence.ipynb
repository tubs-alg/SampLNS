{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence of upper and lower bound over time\n",
    "\n",
    "Note that the events in the plot are only based on the upper bound iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_json(\"./05_clean_data.json.zip\")\n",
    "# data = data.drop_duplicates(subset=[\"instance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extend the data by some additional information on the best values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the best values for each instance as reference.\n",
    "best_solutions = (\n",
    "    data[[\"instance\", \"initial_sample_size\", \"optimized_sample_size\"]]\n",
    "    .groupby(\"instance\")\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"initial_sample_size\": \"best_baseline\",\n",
    "            \"optimized_sample_size\": \"best_lns_ub\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "best_lb = (\n",
    "    data[[\"instance\", \"lower_bound\"]]\n",
    "    .groupby(\"instance\")\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"lower_bound\": \"best_lb\"})\n",
    ")\n",
    "best_values = best_solutions.merge(best_lb, left_on=\"instance\", right_on=\"instance\")\n",
    "# add them to the data as reference\n",
    "data = data.merge(best_values, left_on=\"instance\", right_on=\"instance\")\n",
    "data = data[data[\"baseline_alg\"] == \"FIDE-YASA(m=1)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## A look onto the data never hurts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data field `iteration_info` contains a list of dicts for each iteration. This dict looks as follows:\n",
    "```\n",
    "{ 'nbrhd_tuples': 166,  # the tuples to be covered in this iteration\n",
    "  'nbrhd_confs': 5,     # the number of configurations deleted from the sample\n",
    "  'iteration': 0,       # the number of the iteration, in this case the first iteration\n",
    "  'lb': 3.0,            # the current best lb (global)\n",
    "  'ub': 23,             # the current best ub (global)\n",
    "  'time': 1.0297019481658936,    # overall time at the end of this iteration\n",
    "  'iteration_time': 0.48791050910949707,   # time in this iteration\n",
    "  'events': [[0.0350489616394043, 'neighborhood_selected'],   # times of events in this iteration. Good for finding the culprit of long runtimes.\n",
    "   [0.24133801460266113, 'local_cds_computed'],\n",
    "   [0.29517436027526855, 'model_built'],\n",
    "   [0.48662543296813965, 'model_optimized'],\n",
    "   [0.48789548873901367, 'neighborhood_optimized'],\n",
    "   [0.48791003227233887, 'global_lb_iteration_finished']]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instance_infos = (\n",
    "    data[[\"instance\", \"#Variables\", \"#Clauses\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(by=[\"#Variables\", \"#Clauses\"])\n",
    ")\n",
    "instance_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extract the iteration data from each optimization\n",
    "\n",
    "Bring them in a format that can easily be plotted by seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Collect the data from the iteration_info events.\n",
    "class EventCollector:\n",
    "    def __init__(self):\n",
    "        self.events = {\n",
    "            \"time\": [],\n",
    "            \"val\": [],\n",
    "            \"type\": [],\n",
    "            \"instance\": [],\n",
    "            \"path\": [],\n",
    "            \"alg\": [],\n",
    "            \"initial_sample_size\": [],\n",
    "            \"y\": [],\n",
    "            \"final\": [],\n",
    "        }\n",
    "\n",
    "    def __call__(self, row):\n",
    "        it_data = row[\"iteration_info\"]\n",
    "\n",
    "        def add(val, lbub, time, final=False):\n",
    "            if time > 900:\n",
    "                return\n",
    "            self.events[\"time\"].append(time / 60)\n",
    "            self.events[\"val\"].append(val)\n",
    "            self.events[\"type\"].append(lbub)\n",
    "            self.events[\"instance\"].append(row[\"instance\"])\n",
    "            self.events[\"alg\"].append(row[\"baseline_alg\"])\n",
    "            self.events[\"path\"].append(row[\"initial_sample_path\"])\n",
    "            self.events[\"initial_sample_size\"].append(row[\"initial_sample_size\"])\n",
    "            self.events[\"y\"].append(100 * (val / row[\"best_lb\"]))\n",
    "            self.events[\"final\"].append(final)\n",
    "\n",
    "        # add a zero entry\n",
    "        add(0, \"Lower\", 0)\n",
    "        add(row[\"initial_sample_size\"], \"Upper\", 0)\n",
    "        for event in it_data:\n",
    "            add(\n",
    "                event[\"lb\"],\n",
    "                \"Lower\",\n",
    "                event[\"time\"],\n",
    "                final=event[\"lb\"] == row[\"lower_bound\"],\n",
    "            )\n",
    "            add(\n",
    "                event[\"ub\"],\n",
    "                \"Upper\",\n",
    "                event[\"time\"],\n",
    "                final=event[\"ub\"] == row[\"optimized_sample_size\"],\n",
    "            )\n",
    "\n",
    "\n",
    "ec = EventCollector()\n",
    "data[data[\"baseline_alg\"] == \"FIDE-YASA(m=1)\"].sort_values(\n",
    "    by=[\"#Variables\", \"#Clauses\"]\n",
    ").apply(ec, axis=1)\n",
    "t = pd.DataFrame(ec.events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature Models on which SampLNS did not finish a single iteration in time\n",
    "\n",
    "These models have very large initial samples (more than a thousand configurations), for which the current implementation is not equipped.\n",
    "The problem lies more in the data structures than the actual approach.\n",
    "They should be feasible with some extra effort in making those data structures more efficient.\n",
    "\n",
    "*A lower bound is still computed for these instances, but without iterations of SampLNS, only the final lower bound is saved after SampLNS aborted.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_ = t.groupby([\"instance\", \"path\"])[\"time\"].max().reset_index()\n",
    "unsolved_instances = t_[t_[\"time\"] == 0][\"instance\"].unique().tolist()\n",
    "unsolved_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot the convergence for all other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solved_instances = [\n",
    "    x for x in instance_infos[\"instance\"].tolist() if x not in unsolved_instances\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare plotting\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lb_ub_progress(data, axis, xmax=16, single_instance=False):\n",
    "    instance_descr = \"Model\"\n",
    "    bound_descr = \"Bound\"\n",
    "    t_ = data.rename(columns={\"instance\": instance_descr, \"type\": bound_descr})\n",
    "    if single_instance:\n",
    "        sns.lineplot(\n",
    "            data=t_,\n",
    "            ax=axis,\n",
    "            x=\"time\",\n",
    "            y=\"y\",\n",
    "            style=bound_descr,\n",
    "            hue=\"path\",\n",
    "            units=\"path\",\n",
    "            estimator=None,\n",
    "            markers=False,\n",
    "            palette=\"tab10\",\n",
    "            drawstyle=\"steps-post\",\n",
    "            dashes=[(1.5, 1.5), (3, 3)],\n",
    "            legend=False,\n",
    "        )\n",
    "        sns.scatterplot(\n",
    "            data=t_[t_[bound_descr] == \"Upper\"],\n",
    "            ax=axis,\n",
    "            x=\"time\",\n",
    "            y=\"y\",\n",
    "            hue=\"path\",\n",
    "            marker=\"X\",\n",
    "            palette=\"tab10\",\n",
    "            legend=False,\n",
    "        )\n",
    "    else:\n",
    "        sns.lineplot(\n",
    "            data=t_,\n",
    "            ax=axis,\n",
    "            x=\"time\",\n",
    "            y=\"y\",\n",
    "            style=bound_descr,\n",
    "            hue=instance_descr,\n",
    "            units=\"path\",\n",
    "            estimator=None,\n",
    "            markers=False,\n",
    "            palette=\"tab10\",\n",
    "            drawstyle=\"steps-post\",\n",
    "            dashes=[(1.5, 1.5), (3, 3)],\n",
    "        )\n",
    "        sns.scatterplot(\n",
    "            data=t_[t_[bound_descr] == \"Upper\"],\n",
    "            ax=axis,\n",
    "            x=\"time\",\n",
    "            y=\"y\",\n",
    "            hue=instance_descr,\n",
    "            marker=\"X\",\n",
    "            palette=\"tab10\",\n",
    "            legend=False,\n",
    "        )\n",
    "    axis.set_xlim(-0.1, xmax)\n",
    "    axis.set_xlabel(\"Time in (min)\")\n",
    "    axis.set_ylabel(\"Relative to best lower bound (%)\")\n",
    "    if single_instance:\n",
    "        axis.set_title(\n",
    "            f\"Convergence of upper and lower bound - {data['instance'].tolist()[0]}\"\n",
    "        )\n",
    "    else:\n",
    "        axis.set_title(\"Convergence of upper and lower bound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### All models in one plot\n",
    "\n",
    "This shows us that most models really make quick progress and only a few take a little longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 13))\n",
    "plot_lb_ub_progress(t[t[\"instance\"].isin(solved_instances)], plt.gca(), xmax=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Every model with all its five runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1, len(solved_instances), 1):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plot_lb_ub_progress(\n",
    "        t[t[\"instance\"].isin(solved_instances[i : i + 1])],\n",
    "        plt.gca(),\n",
    "        xmax=15.1,\n",
    "        single_instance=True,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Looking onto a selection of instances in a single plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ec = EventCollector()\n",
    "selection = [\n",
    "    \"PPU\",\n",
    "    # small, optimal initial sample, no improvement, reached lower bound, progress within seconds + largest system for which an existing sampling algorithm is optimal\n",
    "    \"axTLS\",\n",
    "    # small, bad initial sample, large improvement, tight lower bound, progress for 0/1 min + smallest system that we cannot optimally solve\n",
    "    \"berkeleyDB2\",\n",
    "    # small, bad initial sample, large improvement, reached lower bound, progress for 6/3 min + one of the most significant improvements (43% + optimal afterwards)\n",
    "    \"fs_2017-05-22\",\n",
    "    # medium, good initial sample, small improvement, tight lower bound, progress for 0/10 min + smallest improvement (near-optimal sample still improved)\n",
    "    \"busybox_2020-12-16_21-53-05\",\n",
    "    # medium, bad initial sample, improvement over ~6 minutes, quick progress on lb.\n",
    "    \"FreeBSD-8_0_0\"\n",
    "    # medium, bad initial sample, large improvement, far lower bound, progress for 15/15 min + system with the largest remaining gap between LB=30 and sample=59 (almost 100%)\n",
    "]\n",
    "data[data[\"instance\"].isin(selection)].drop_duplicates(subset=[\"instance\"]).sort_values(\n",
    "    by=[\"#Variables\", \"#Clauses\"]\n",
    ").apply(ec, axis=1)\n",
    "t_selected = pd.DataFrame(ec.events)\n",
    "t_selected[\"instance\"] = t_selected[\"instance\"].apply(lambda s: s[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4.5))\n",
    "plot_lb_ub_progress(t_selected, plt.gca(), xmax=16)\n",
    "plt.legend(ncols=3, loc=\"lower right\", prop={\"size\": 10})\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./plots/01_12_convergence_of_selected_models.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Time of last change\n",
    "\n",
    "To get a better grasp of the necessary time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_until_last_change = (\n",
    "    t[t[\"final\"] & (t[\"instance\"].isin(solved_instances))]\n",
    "    .groupby([\"instance\", \"path\", \"type\"])[[\"time\"]]\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .groupby([\"instance\", \"type\"])[[\"time\"]]\n",
    "    .mean()\n",
    ")\n",
    "time_until_last_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(time_until_last_change.groupby(\"instance\")[[\"time\"]].max() < 3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_until_last_change.reset_index().groupby(\"type\")[[\"time\"]].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
