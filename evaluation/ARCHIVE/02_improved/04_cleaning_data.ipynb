{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Cleaning the data and providing a small and easily parsable database.\n",
    "\n",
    "The database with the full logs is too huge to work on. Most of the data would only be needed for debugging but not for evaluation.\n",
    "Thus, we create a clean and small database for the further evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algbench import read_as_pandas, Benchmark\n",
    "from _utils import parse_solution_overview, parse_sample\n",
    "\n",
    "\n",
    "def get_results(input_sample_archive, result_folder, max_vars=1500):\n",
    "    # Loading the data of the experiment.\n",
    "\n",
    "    # Merge the new data with the data of the initial samples\n",
    "    data = read_as_pandas(\n",
    "        result_folder,\n",
    "        lambda result: {\n",
    "            \"parameters\": result[\"parameters\"],\n",
    "            \"initial_sample_path\": result[\"parameters\"][\"args\"][\"initial_sample_path\"],\n",
    "            \"instance_name\": result[\"parameters\"][\"args\"][\"instance_name\"],\n",
    "            \"lower_bound\": result[\"result\"][\"lower_bound\"],\n",
    "            \"upper_bound\": result[\"result\"][\"upper_bound\"],\n",
    "            \"iteration_info\": result[\"result\"][\"iteration_info\"],\n",
    "            \"instance\": result[\"parameters\"][\"args\"][\"instance_name\"],\n",
    "        }\n",
    "        if result[\"result\"]\n",
    "        else None,\n",
    "    )\n",
    "\n",
    "    data_initial = parse_solution_overview(input_sample_archive)\n",
    "    data = data.merge(data_initial, left_on=\"initial_sample_path\", right_on=\"Path\")\n",
    "\n",
    "    # add a good name for 00_baseline algorithms including the settings\n",
    "    def baseline_alg_name(row):\n",
    "        settings = row[\"Settings\"]\n",
    "        if \"_m\" in settings:\n",
    "            m = settings.split(\"_m\")[-1].split(\"_\")[0]\n",
    "            return f\"{row['Algorithm']}(m={m})\"\n",
    "        return row[\"Algorithm\"]\n",
    "\n",
    "    data[\"baseline_alg\"] = data.apply(baseline_alg_name, axis=1)\n",
    "    n = len(data)\n",
    "    data = data[data[\"#Variables\"] <= max_vars].copy()\n",
    "    print(f\"Removed {n-len(data)} results because of size constraint.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the data folders: {'2023-03-01_13-51-03/'}\n",
      "Removed 0 results because of size constraint.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the data of the experiment.\n",
    "\n",
    "\n",
    "# CHECK THAT THESE ARE THE CORRECT PATHS!\n",
    "TIME_LIMIT = 900\n",
    "\n",
    "BASE = \"900_seconds_5_it\"\n",
    "INPUT_SAMPLE_ARCHIVE = f\"../01_ICSE_2024_0/00_baseline/{BASE}.zip\"\n",
    "INSTANCE_ARCHIVE = \"../01_ICSE_2024_0//00_benchmark_instances.zip\"\n",
    "RESULT_FOLDER = f\"01_results/{BASE}_{TIME_LIMIT}\"\n",
    "\n",
    "\n",
    "def recache_data():\n",
    "    relevant_columns = [\n",
    "        \"instance\",\n",
    "        \"#Variables\",\n",
    "        \"#Clauses\",\n",
    "        \"iteration_info\",\n",
    "        \"baseline_alg\",\n",
    "        \"initial_sample_path\",\n",
    "        \"SampleSize\",\n",
    "        \"lower_bound\",\n",
    "        \"upper_bound\",\n",
    "    ]\n",
    "    data = get_results(\n",
    "        input_sample_archive=INPUT_SAMPLE_ARCHIVE, result_folder=RESULT_FOLDER\n",
    "    )[relevant_columns]\n",
    "    data.rename(\n",
    "        columns={\n",
    "            \"SampleSize\": \"initial_sample_size\",\n",
    "            \"upper_bound\": \"optimized_sample_size\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    data.drop_duplicates(subset=[\"initial_sample_path\"], inplace=True)\n",
    "    data.to_json(\"./05_clean_data.json.zip\")\n",
    "    del data\n",
    "\n",
    "\n",
    "recache_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance</th>\n",
       "      <th>#Variables</th>\n",
       "      <th>#Clauses</th>\n",
       "      <th>iteration_info</th>\n",
       "      <th>baseline_alg</th>\n",
       "      <th>initial_sample_path</th>\n",
       "      <th>initial_sample_size</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>optimized_sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>email</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>[{'nbrhd_tuples': 70, 'nbrhd_confs': 8, 'itera...</td>\n",
       "      <td>FIDE-YASA(m=1)</td>\n",
       "      <td>2023-03-01_13-51-03/3_1_3_5_sample.csv</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChatClient</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>[{'nbrhd_tuples': 176, 'nbrhd_confs': 10, 'ite...</td>\n",
       "      <td>FIDE-YASA(m=1)</td>\n",
       "      <td>2023-03-01_13-51-03/4_1_3_1_sample.csv</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChatClient</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>[{'nbrhd_tuples': 176, 'nbrhd_confs': 10, 'ite...</td>\n",
       "      <td>FIDE-YASA(m=1)</td>\n",
       "      <td>2023-03-01_13-51-03/4_1_3_2_sample.csv</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChatClient</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>[{'nbrhd_tuples': 176, 'nbrhd_confs': 10, 'ite...</td>\n",
       "      <td>FIDE-YASA(m=1)</td>\n",
       "      <td>2023-03-01_13-51-03/4_1_3_3_sample.csv</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChatClient</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>[{'nbrhd_tuples': 176, 'nbrhd_confs': 10, 'ite...</td>\n",
       "      <td>FIDE-YASA(m=1)</td>\n",
       "      <td>2023-03-01_13-51-03/4_1_3_4_sample.csv</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>berkeleyDB2</td>\n",
       "      <td>119</td>\n",
       "      <td>346</td>\n",
       "      <td>[{'nbrhd_tuples': 198, 'nbrhd_confs': 10, 'ite...</td>\n",
       "      <td>Incling</td>\n",
       "      <td>2023-03-01_13-51-03/20_1_2_5_sample.csv</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>soletta_2015-06-26_18-38-56</td>\n",
       "      <td>129</td>\n",
       "      <td>192</td>\n",
       "      <td>[{'nbrhd_tuples': 223, 'nbrhd_confs': 22, 'ite...</td>\n",
       "      <td>Incling</td>\n",
       "      <td>2023-03-01_13-51-03/21_1_2_1_sample.csv</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>soletta_2015-06-26_18-38-56</td>\n",
       "      <td>129</td>\n",
       "      <td>192</td>\n",
       "      <td>[{'nbrhd_tuples': 227, 'nbrhd_confs': 22, 'ite...</td>\n",
       "      <td>Incling</td>\n",
       "      <td>2023-03-01_13-51-03/21_1_2_2_sample.csv</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>soletta_2015-06-26_18-38-56</td>\n",
       "      <td>129</td>\n",
       "      <td>192</td>\n",
       "      <td>[{'nbrhd_tuples': 193, 'nbrhd_confs': 21, 'ite...</td>\n",
       "      <td>Incling</td>\n",
       "      <td>2023-03-01_13-51-03/21_1_2_3_sample.csv</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>soletta_2015-06-26_18-38-56</td>\n",
       "      <td>129</td>\n",
       "      <td>192</td>\n",
       "      <td>[{'nbrhd_tuples': 247, 'nbrhd_confs': 26, 'ite...</td>\n",
       "      <td>Incling</td>\n",
       "      <td>2023-03-01_13-51-03/21_1_2_4_sample.csv</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1938 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         instance  #Variables  #Clauses  \\\n",
       "0                           email          10        17   \n",
       "1                      ChatClient          14        20   \n",
       "2                      ChatClient          14        20   \n",
       "3                      ChatClient          14        20   \n",
       "4                      ChatClient          14        20   \n",
       "...                           ...         ...       ...   \n",
       "1933                  berkeleyDB2         119       346   \n",
       "1934  soletta_2015-06-26_18-38-56         129       192   \n",
       "1935  soletta_2015-06-26_18-38-56         129       192   \n",
       "1936  soletta_2015-06-26_18-38-56         129       192   \n",
       "1937  soletta_2015-06-26_18-38-56         129       192   \n",
       "\n",
       "                                         iteration_info    baseline_alg  \\\n",
       "0     [{'nbrhd_tuples': 70, 'nbrhd_confs': 8, 'itera...  FIDE-YASA(m=1)   \n",
       "1     [{'nbrhd_tuples': 176, 'nbrhd_confs': 10, 'ite...  FIDE-YASA(m=1)   \n",
       "2     [{'nbrhd_tuples': 176, 'nbrhd_confs': 10, 'ite...  FIDE-YASA(m=1)   \n",
       "3     [{'nbrhd_tuples': 176, 'nbrhd_confs': 10, 'ite...  FIDE-YASA(m=1)   \n",
       "4     [{'nbrhd_tuples': 176, 'nbrhd_confs': 10, 'ite...  FIDE-YASA(m=1)   \n",
       "...                                                 ...             ...   \n",
       "1933  [{'nbrhd_tuples': 198, 'nbrhd_confs': 10, 'ite...         Incling   \n",
       "1934  [{'nbrhd_tuples': 223, 'nbrhd_confs': 22, 'ite...         Incling   \n",
       "1935  [{'nbrhd_tuples': 227, 'nbrhd_confs': 22, 'ite...         Incling   \n",
       "1936  [{'nbrhd_tuples': 193, 'nbrhd_confs': 21, 'ite...         Incling   \n",
       "1937  [{'nbrhd_tuples': 247, 'nbrhd_confs': 26, 'ite...         Incling   \n",
       "\n",
       "                          initial_sample_path  initial_sample_size  \\\n",
       "0      2023-03-01_13-51-03/3_1_3_5_sample.csv                    8   \n",
       "1      2023-03-01_13-51-03/4_1_3_1_sample.csv                   10   \n",
       "2      2023-03-01_13-51-03/4_1_3_2_sample.csv                   10   \n",
       "3      2023-03-01_13-51-03/4_1_3_3_sample.csv                   10   \n",
       "4      2023-03-01_13-51-03/4_1_3_4_sample.csv                   10   \n",
       "...                                       ...                  ...   \n",
       "1933  2023-03-01_13-51-03/20_1_2_5_sample.csv                   28   \n",
       "1934  2023-03-01_13-51-03/21_1_2_1_sample.csv                   44   \n",
       "1935  2023-03-01_13-51-03/21_1_2_2_sample.csv                   44   \n",
       "1936  2023-03-01_13-51-03/21_1_2_3_sample.csv                   44   \n",
       "1937  2023-03-01_13-51-03/21_1_2_4_sample.csv                   44   \n",
       "\n",
       "      lower_bound  optimized_sample_size  \n",
       "0               6                      6  \n",
       "1               7                      7  \n",
       "2               7                      7  \n",
       "3               7                      7  \n",
       "4               7                      7  \n",
       "...           ...                    ...  \n",
       "1933           11                     12  \n",
       "1934           24                     24  \n",
       "1935           24                     24  \n",
       "1936           24                     24  \n",
       "1937           24                     24  \n",
       "\n",
       "[1938 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"./05_clean_data.json.zip\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* `instance` Unique name of feature model.\n",
    "* `#Variables` Number of variables in model.\n",
    "* `#Clauses` Number of clauses in model.\n",
    "* `iteration_info` Information on the individual iterations (needs some additional processing)\n",
    "* `baseline_alg` Name of the algorithm that computed the initial sample.\n",
    "* `initial_sample_path` Path to the initial sample in the database (for querying, but it also serves as identifier).\n",
    "* `initial_sample_size` Size of the initial sample.\n",
    "* `lower_bound` The lower bound computed by SampLNS.\n",
    "* `optimized_sample_size` Size of the sample after optimization with SampLNS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
